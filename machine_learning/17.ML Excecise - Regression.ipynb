{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["pGwaKfZVIkdE"],"authorship_tag":"ABX9TyOSr4lusvNSxIQozoNgiT5R"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Objective\n","Objective is to build a predictive model that predicts the cost of health insurance based on the customer's demography and habits.\n","\n","In this excercise, we will try out multiple regression algorithm and see which one gives the best result.\n","\n","Reference:\n","https://www.kaggle.com/code/ahmetemirdundar/medical-cost-prediction/notebook"],"metadata":{"id":"hb2XliD_q3nY"}},{"cell_type":"code","source":["# Connect to Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zeTMLS37sgck","executionInfo":{"status":"ok","timestamp":1755433446294,"user_tz":300,"elapsed":12402,"user":{"displayName":"Bibhu Mishra","userId":"12646824449670614646"}},"outputId":"3ff1b959-d41d-47d3-996e-820d2d50c107"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["## EDA"],"metadata":{"id":"pGwaKfZVIkdE"}},{"cell_type":"code","source":["# Import required packages\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_squared_error, r2_score"],"metadata":{"id":"_QCNwZV4sqFL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load Data\n","df = pd.read_csv('/content/drive/MyDrive/edurekaai/_data/insurance_cost.csv')\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"KFFLsGGHs1Tz","executionInfo":{"status":"ok","timestamp":1755433469345,"user_tz":300,"elapsed":1725,"user":{"displayName":"Bibhu Mishra","userId":"12646824449670614646"}},"outputId":"0891ee51-a3cc-47a5-aa13-050b396a2579"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   age     sex     bmi  children smoker     region      charges\n","0   19  female  27.900         0    yes  southwest  16884.92400\n","1   18    male  33.770         1     no  southeast   1725.55230\n","2   28    male  33.000         3     no  southeast   4449.46200\n","3   33    male  22.705         0     no  northwest  21984.47061\n","4   32    male  28.880         0     no  northwest   3866.85520"],"text/html":["\n","  <div id=\"df-b02abb12-4c52-4d13-8381-5b52cc205f38\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>sex</th>\n","      <th>bmi</th>\n","      <th>children</th>\n","      <th>smoker</th>\n","      <th>region</th>\n","      <th>charges</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>19</td>\n","      <td>female</td>\n","      <td>27.900</td>\n","      <td>0</td>\n","      <td>yes</td>\n","      <td>southwest</td>\n","      <td>16884.92400</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>18</td>\n","      <td>male</td>\n","      <td>33.770</td>\n","      <td>1</td>\n","      <td>no</td>\n","      <td>southeast</td>\n","      <td>1725.55230</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>28</td>\n","      <td>male</td>\n","      <td>33.000</td>\n","      <td>3</td>\n","      <td>no</td>\n","      <td>southeast</td>\n","      <td>4449.46200</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>33</td>\n","      <td>male</td>\n","      <td>22.705</td>\n","      <td>0</td>\n","      <td>no</td>\n","      <td>northwest</td>\n","      <td>21984.47061</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>32</td>\n","      <td>male</td>\n","      <td>28.880</td>\n","      <td>0</td>\n","      <td>no</td>\n","      <td>northwest</td>\n","      <td>3866.85520</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b02abb12-4c52-4d13-8381-5b52cc205f38')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-b02abb12-4c52-4d13-8381-5b52cc205f38 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-b02abb12-4c52-4d13-8381-5b52cc205f38');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-924ea6ca-9680-4e5b-9881-b60f86a76a15\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-924ea6ca-9680-4e5b-9881-b60f86a76a15')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-924ea6ca-9680-4e5b-9881-b60f86a76a15 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 1338,\n  \"fields\": [\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14,\n        \"min\": 18,\n        \"max\": 64,\n        \"num_unique_values\": 47,\n        \"samples\": [\n          21,\n          45,\n          36\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sex\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"male\",\n          \"female\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bmi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.098186911679017,\n        \"min\": 15.96,\n        \"max\": 53.13,\n        \"num_unique_values\": 548,\n        \"samples\": [\n          23.18,\n          26.885\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"children\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"smoker\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"no\",\n          \"yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"region\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"southeast\",\n          \"northeast\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"charges\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12110.011236693994,\n        \"min\": 1121.8739,\n        \"max\": 63770.42801,\n        \"num_unique_values\": 1337,\n        \"samples\": [\n          8688.85885,\n          5708.867\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["df.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r_OqhsfQtZit","executionInfo":{"status":"ok","timestamp":1755380982496,"user_tz":300,"elapsed":67,"user":{"displayName":"Bibhu Mishra","userId":"12646824449670614646"}},"outputId":"a3d38f34-87f1-47a7-9760-95b9fd57390b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1338 entries, 0 to 1337\n","Data columns (total 7 columns):\n"," #   Column    Non-Null Count  Dtype  \n","---  ------    --------------  -----  \n"," 0   age       1338 non-null   int64  \n"," 1   sex       1338 non-null   object \n"," 2   bmi       1338 non-null   float64\n"," 3   children  1338 non-null   int64  \n"," 4   smoker    1338 non-null   object \n"," 5   region    1338 non-null   object \n"," 6   charges   1338 non-null   float64\n","dtypes: float64(2), int64(2), object(3)\n","memory usage: 73.3+ KB\n"]}]},{"cell_type":"code","source":["# Basic Stastical Analysis\n","df.describe()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"id":"bqLWnpTStJHw","executionInfo":{"status":"ok","timestamp":1755380984342,"user_tz":300,"elapsed":33,"user":{"displayName":"Bibhu Mishra","userId":"12646824449670614646"}},"outputId":"f8c2bd16-d517-4119-90e0-4d252e34a826"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["               age          bmi     children       charges\n","count  1338.000000  1338.000000  1338.000000   1338.000000\n","mean     39.207025    30.663397     1.094918  13270.422265\n","std      14.049960     6.098187     1.205493  12110.011237\n","min      18.000000    15.960000     0.000000   1121.873900\n","25%      27.000000    26.296250     0.000000   4740.287150\n","50%      39.000000    30.400000     1.000000   9382.033000\n","75%      51.000000    34.693750     2.000000  16639.912515\n","max      64.000000    53.130000     5.000000  63770.428010"],"text/html":["\n","  <div id=\"df-6e80239d-3de1-4384-9ba5-4a41413f63a5\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>bmi</th>\n","      <th>children</th>\n","      <th>charges</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>1338.000000</td>\n","      <td>1338.000000</td>\n","      <td>1338.000000</td>\n","      <td>1338.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>39.207025</td>\n","      <td>30.663397</td>\n","      <td>1.094918</td>\n","      <td>13270.422265</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>14.049960</td>\n","      <td>6.098187</td>\n","      <td>1.205493</td>\n","      <td>12110.011237</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>18.000000</td>\n","      <td>15.960000</td>\n","      <td>0.000000</td>\n","      <td>1121.873900</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>27.000000</td>\n","      <td>26.296250</td>\n","      <td>0.000000</td>\n","      <td>4740.287150</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>39.000000</td>\n","      <td>30.400000</td>\n","      <td>1.000000</td>\n","      <td>9382.033000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>51.000000</td>\n","      <td>34.693750</td>\n","      <td>2.000000</td>\n","      <td>16639.912515</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>64.000000</td>\n","      <td>53.130000</td>\n","      <td>5.000000</td>\n","      <td>63770.428010</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e80239d-3de1-4384-9ba5-4a41413f63a5')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-6e80239d-3de1-4384-9ba5-4a41413f63a5 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-6e80239d-3de1-4384-9ba5-4a41413f63a5');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-662416ad-bd03-4c95-9bca-199179fbf58a\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-662416ad-bd03-4c95-9bca-199179fbf58a')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-662416ad-bd03-4c95-9bca-199179fbf58a button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 460.6106090399993,\n        \"min\": 14.049960379216172,\n        \"max\": 1338.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          39.20702541106129,\n          39.0,\n          1338.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bmi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 463.29524977918294,\n        \"min\": 6.098186911679017,\n        \"max\": 1338.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          30.66339686098655,\n          30.4,\n          1338.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"children\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 472.5368318870757,\n        \"min\": 0.0,\n        \"max\": 1338.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1338.0,\n          1.0949177877429,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"charges\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20381.922846226596,\n        \"min\": 1121.8739,\n        \"max\": 63770.42801,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          13270.422265141257,\n          9382.033,\n          1338.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["**Insight - 1**\n","- sex, smoker, and region are categorical features\n","- age, bmi, children, and charges are numerical features.\n","- No null or missing value present.\n","- Age IQR (75% - 25%) is 24\n","- Age Relative IQR (IQR/median(50%)) = 24/39 = 0.6153 = 61.53%. It means age has high variation or spread. **_Random Forest and XGBoost handles variaations better._**\n","- Mean and Median of  Age ~39. Suggesting minimal or no skew.\n","\n","- BMI IQR (75% - 25%) is  8.3975\n","- BMI Relative IQR (IQR/Median) = 8.3975/30.40 = .27 = 27%. Moderate variation.\n","- Mean and Median of BMI ~30. Suggesting mininal or no skew.\n","\n","- Age Min-Max range is 48m, bmi range is 38, and charges range is 51000. It mean, we must apply scaling."],"metadata":{"id":"YQJdHN_Oyp-I"}},{"cell_type":"code","source":["# Verify the skewness\n","import pandas as pd\n","print(df[['age', 'bmi', 'charges']].skew())\n","\n","\n","# **Skewness Interpretation:**\n","# ```\n","# -   ≈ 0 → fairly symmetric\n","# -   > 0.5 → moderate right skew\n","# -   > 1 → strong right skew\n","# -   < -0.5 → moderate left skew\n","# -   < -1 → strong left skew\n","# ```"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0ChId6SH2qQd","executionInfo":{"status":"ok","timestamp":1755381150537,"user_tz":300,"elapsed":70,"user":{"displayName":"Bibhu Mishra","userId":"12646824449670614646"}},"outputId":"4713e5f7-4b29-49ed-c177-12321b4f9114"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["age        0.055673\n","bmi        0.284047\n","charges    1.515880\n","dtype: float64\n"]}]},{"cell_type":"code","source":["# Verify outliers\n","def detect_outliers_iqr(series):\n","    Q1 = series.quantile(0.25)\n","    Q3 = series.quantile(0.75)\n","    IQR = Q3 - Q1\n","    lower_bound = Q1 - 1.5 * IQR\n","    upper_bound = Q3 + 1.5 * IQR\n","    outliers = series[(series < lower_bound) | (series > upper_bound)]\n","    return outliers\n","\n","age_outliers = detect_outliers_iqr(df['age'])\n","bmi_outliers = detect_outliers_iqr(df['bmi'])\n","charges_outliers = detect_outliers_iqr(df['charges'])\n","\n","print(f\"Age outliers count: {len(age_outliers)}\")\n","print(f\"Salary outliers count: {len(bmi_outliers)}\")\n","print(f\"Charges outliers count: {len(charges_outliers)}\")\n","\n","# Interpretation:\n","# If the count of outliers is significant, it may indicate that the data has extreme values\n","# that could affect the model's performance. Further investigation is needed to determine\n","# whether to remove or treat these outliers.\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8j8W576A3udL","executionInfo":{"status":"ok","timestamp":1755381232395,"user_tz":300,"elapsed":29,"user":{"displayName":"Bibhu Mishra","userId":"12646824449670614646"}},"outputId":"0e255f74-7cc0-445a-971b-359c73afd7ae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Age outliers count: 0\n","Salary outliers count: 9\n","Charges outliers count: 139\n"]}]},{"cell_type":"markdown","source":["**Insight - 2**\n","- target feature (charges) has high skewness, and has multiple outliers. Hence, the feature must be scaled using logarithim scaling.\n"],"metadata":{"id":"UL0JUypB4Jz2"}},{"cell_type":"markdown","source":["#### Peform Categorical Analysis"],"metadata":{"id":"rKhzGoh64fYU"}},{"cell_type":"code","source":["print(df['sex'].value_counts(normalize=True) * 100)\n","print(df['smoker'].value_counts(normalize=True) * 100)\n","print(df['region'].value_counts(normalize=True) * 100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6x5-4tvb4pVM","executionInfo":{"status":"ok","timestamp":1755381461629,"user_tz":300,"elapsed":32,"user":{"displayName":"Bibhu Mishra","userId":"12646824449670614646"}},"outputId":"99b65d7d-a0eb-43b3-ff01-7fd07e1c9428"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["sex\n","male      50.523169\n","female    49.476831\n","Name: proportion, dtype: float64\n","smoker\n","no     79.521674\n","yes    20.478326\n","Name: proportion, dtype: float64\n","region\n","southeast    27.204783\n","southwest    24.289985\n","northwest    24.289985\n","northeast    24.215247\n","Name: proportion, dtype: float64\n"]}]},{"cell_type":"markdown","source":["**Insight - 3**\n","- sex and region classes seems equally distributed.\n","- feature smoker look imbalanced in the dataset. Hence, Consider using stratified sampling when splitting train/test."],"metadata":{"id":"ma5fIkw048mA"}},{"cell_type":"markdown","source":["## Preprocessing the data"],"metadata":{"id":"qWq73Sgg5U4q"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","# Load Data\n","df = pd.read_csv('/content/drive/MyDrive/edurekaai/_data/insurance_cost.csv')\n","df.head()\n","\n","# Fix missing values\n","## No missing or null values\n","print(df.info())\n","\n","# Features & target\n","X = df.drop(columns=[\"charges\"])\n","y = df[\"charges\"]\n","\n","# Train/test split\n","X_train, X_test, y_train, y_test = train_test_split(X, y,\n","                                                    test_size=0.2,\n","                                                    random_state=42,\n","                                                    stratify=X[\"smoker\"]\n","                                                    )\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oSIxXtGc5Y4Q","executionInfo":{"status":"ok","timestamp":1755436146543,"user_tz":300,"elapsed":52,"user":{"displayName":"Bibhu Mishra","userId":"12646824449670614646"}},"outputId":"66948691-328b-49fc-fae9-5bba4352421d"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1338 entries, 0 to 1337\n","Data columns (total 7 columns):\n"," #   Column    Non-Null Count  Dtype  \n","---  ------    --------------  -----  \n"," 0   age       1338 non-null   int64  \n"," 1   sex       1338 non-null   object \n"," 2   bmi       1338 non-null   float64\n"," 3   children  1338 non-null   int64  \n"," 4   smoker    1338 non-null   object \n"," 5   region    1338 non-null   object \n"," 6   charges   1338 non-null   float64\n","dtypes: float64(2), int64(2), object(3)\n","memory usage: 73.3+ KB\n","None\n"]}]},{"cell_type":"markdown","source":["## Linear Regression"],"metadata":{"id":"E4WQZ9gJJjAD"}},{"cell_type":"code","source":["\"\"\"\n","Insurance Cost Prediction using Linear Regression with a Scikit-Learn Pipeline\n","------------------------------------------------------------------------------\n","\n","This script demonstrates how to build a machine learning pipeline for regression\n","tasks (predicting insurance charges). It includes preprocessing steps for\n","numerical and categorical features, log transformation of skewed values,\n","and model evaluation with regression metrics.\n","\n","Key Steps:\n","1. Preprocessing numerical & categorical features.\n","2. Building a full ML pipeline with Linear Regression.\n","3. Training & predicting on train/test data.\n","4. Evaluating performance using regression metrics.\n","\"\"\"\n","\n","# -----------------------------\n","# Imports\n","# -----------------------------\n","import numpy as np\n","import pandas as pd\n","\n","# Preprocessing & pipeline tools\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n","from sklearn.impute import SimpleImputer\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","\n","# Model\n","from sklearn.linear_model import LinearRegression\n","\n","# Evaluation metrics (for regression)\n","from sklearn.metrics import (\n","    mean_squared_error,\n","    mean_absolute_error,\n","    mean_absolute_percentage_error,\n","    r2_score,\n","    explained_variance_score\n",")\n","\n","# -----------------------------\n","# Load Dataset\n","# -----------------------------\n","# Example: load your insurance dataset\n","# df = pd.read_csv(\"/content/drive/MyDrive/edurekaai/_data/insurance_cost.csv\")\n","\n","# Define features and target\n","# X = df.drop(columns=[\"charges\"])\n","# y = df[\"charges\"]\n","\n","# Assume X_train, X_test, y_train, y_test are already created\n","# (e.g., using train_test_split)\n","\n","# -----------------------------\n","# Feature Types\n","# -----------------------------\n","# Separate numerical and categorical feature names\n","numerical_features = X_train.select_dtypes(exclude=[\"object\", \"category\"]).columns\n","categorical_features = X_train.select_dtypes(include=[\"object\", \"category\"]).columns\n","\n","# -----------------------------\n","# Preprocessing Pipelines\n","# -----------------------------\n","\n","# 1. Numerical Transformer:\n","#    - Fill missing values with median\n","#    - Apply log transformation to reduce skewness\n","#    - Standardize features (mean=0, variance=1)\n","num_transformer = Pipeline(steps=[\n","    (\"imputer\", SimpleImputer(strategy=\"median\")),\n","    (\"log\", FunctionTransformer(np.log1p, validate=True)),\n","    (\"scaler\", StandardScaler())\n","])\n","\n","# 2. Categorical Transformer:\n","#    - Apply OneHotEncoding to handle categorical variables\n","#    - Ignore unknown categories at prediction time\n","cat_transformer = Pipeline(steps=[\n","    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n","])\n","\n","# 3. Combine Numerical & Categorical Preprocessing\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        (\"num\", num_transformer, numerical_features),\n","        (\"cat\", cat_transformer, categorical_features)\n","    ]\n",")\n","\n","# -----------------------------\n","# Full Model Pipeline\n","# -----------------------------\n","# Combine preprocessing and regression into a single pipeline\n","model = Pipeline(steps=[\n","    (\"preprocessor\", preprocessor),\n","    (\"regressor\", LinearRegression())\n","])\n","\n","# -----------------------------\n","# Model Training\n","# -----------------------------\n","# Log-transform target manually before fitting\n","# y_train_log = np.log1p(y_train)\n","# Train the pipeline on training data\n","model.fit(X_train, y_train)\n","\n","# -----------------------------\n","# Prediction\n","# -----------------------------\n","# Predict on test set\n","# Note: Target 'charges' is log-transformed inside pipeline\n","#       so we need to apply inverse transform (expm1)\n","# y_pred_log = model.predict(X_test)\n","# y_pred = np.expm1(y_pred_log)\n","y_pred = model.predict(X_test)\n","\n","# -----------------------------\n","# Model Evaluation\n","# -----------------------------\n","# classification_metrics = {\n","#     \"Accuracy\": accuracy_score(y_test, y_pred),\n","#     \"Precision\": precision_score(y_test, y_pred, average=self.average, zero_division=0),\n","#     \"Recall\": recall_score(y_test, y_pred, average=self.average, zero_division=0),\n","#     \"F1 Score\": f1_score(y_test, y_pred, average=self.average, zero_division=0),\n","#     \"Confusion Matrix\": confusion_matrix(y_test, y_pred).tolist(),\n","#     \"Classification Report\": classification_report(y_test, y_pred, output_dict=True)\n","# }\n","\n","regression_metrics = {\n","    \"Mean Squared Error\": mean_squared_error(y_test, y_pred),\n","    \"Root Mean Squared Error\": np.sqrt(mean_squared_error(y_test, y_pred)),\n","    \"Mean Absolute Error\": mean_absolute_error(y_test, y_pred),\n","    \"Mean Absolute Percentage Error\": mean_absolute_percentage_error(y_test, y_pred),\n","    \"R-Squared\": r2_score(y_test, y_pred),\n","    \"Explained Variance\": explained_variance_score(y_test, y_pred)\n","}\n","\n","# Print metrics\n","for metric_name, metric_value in regression_metrics.items():\n","    print(f\"{metric_name}: {metric_value:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0W0PsFVqJmNo","executionInfo":{"status":"ok","timestamp":1755436492876,"user_tz":300,"elapsed":41,"user":{"displayName":"Bibhu Mishra","userId":"12646824449670614646"}},"outputId":"64b3098b-3cd8-4ae5-844a-6760ba09685e"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean Squared Error: 32110691.4003\n","Root Mean Squared Error: 5666.6296\n","Mean Absolute Error: 4044.3056\n","Mean Absolute Percentage Error: 0.4177\n","R-Squared: 0.7823\n","Explained Variance: 0.7824\n"]}]},{"cell_type":"markdown","source":["## Decission Tree"],"metadata":{"id":"A82cj9RMK56A"}},{"cell_type":"code","source":["\"\"\"\n","Insurance Cost Prediction using Decision Tree Regressor with a Scikit-Learn Pipeline\n","-----------------------------------------------------------------------------------\n","\n","This script demonstrates how to build a machine learning pipeline for regression\n","tasks (predicting insurance charges). It includes preprocessing steps for\n","numerical and categorical features, and model evaluation with regression metrics.\n","\n","Key Steps:\n","1. Preprocessing numerical & categorical features.\n","2. Building a full ML pipeline with Decision Tree Regressor.\n","3. Training & predicting on train/test data.\n","4. Evaluating performance using regression metrics.\n","\"\"\"\n","\n","# -----------------------------\n","# Imports\n","# -----------------------------\n","import numpy as np\n","import pandas as pd\n","\n","# Preprocessing & pipeline tools\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n","from sklearn.impute import SimpleImputer\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","\n","# Model\n","from sklearn.tree import DecisionTreeRegressor\n","\n","# Evaluation metrics (for regression)\n","from sklearn.metrics import (\n","    mean_squared_error,\n","    mean_absolute_error,\n","    mean_absolute_percentage_error,\n","    r2_score,\n","    explained_variance_score\n",")\n","\n","# -----------------------------\n","# Load Dataset\n","# -----------------------------\n","# Example: load your insurance dataset\n","# df = pd.read_csv(\"/content/drive/MyDrive/edurekaai/_data/insurance_cost.csv\")\n","\n","# Define features and target\n","# X = df.drop(columns=[\"charges\"])\n","# y = df[\"charges\"]\n","\n","# Assume X_train, X_test, y_train, y_test are already created\n","# (e.g., using train_test_split)\n","\n","# -----------------------------\n","# Feature Types\n","# -----------------------------\n","# Separate numerical and categorical feature names\n","numerical_features = X_train.select_dtypes(exclude=[\"object\", \"category\"]).columns\n","categorical_features = X_train.select_dtypes(include=[\"object\", \"category\"]).columns\n","\n","# -----------------------------\n","# Preprocessing Pipelines\n","# -----------------------------\n","\n","# 1. Numerical Transformer:\n","#    - Fill missing values with median\n","#    - Standardize features (optional for trees, but kept for consistency)\n","num_transformer = Pipeline(steps=[\n","    (\"imputer\", SimpleImputer(strategy=\"median\")),\n","    (\"scaler\", StandardScaler())\n","])\n","\n","# 2. Categorical Transformer:\n","#    - Apply OneHotEncoding to handle categorical variables\n","#    - Ignore unknown categories at prediction time\n","cat_transformer = Pipeline(steps=[\n","    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n","])\n","\n","# 3. Combine Numerical & Categorical Preprocessing\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        (\"num\", num_transformer, numerical_features),\n","        (\"cat\", cat_transformer, categorical_features)\n","    ]\n",")\n","\n","# -----------------------------\n","# Full Model Pipeline\n","# -----------------------------\n","# Combine preprocessing and regression into a single pipeline\n","model = Pipeline(steps=[\n","    (\"preprocessor\", preprocessor),\n","    (\"regressor\", DecisionTreeRegressor(random_state=42, max_depth=6))\n","])\n","\n","# -----------------------------\n","# Model Training\n","# -----------------------------\n","# Train the pipeline on training data\n","model.fit(X_train, y_train)\n","\n","# -----------------------------\n","# Prediction\n","# -----------------------------\n","y_pred = model.predict(X_test)\n","\n","# -----------------------------\n","# Model Evaluation\n","# -----------------------------\n","regression_metrics = {\n","    \"Mean Squared Error\": mean_squared_error(y_test, y_pred),\n","    \"Root Mean Squared Error\": np.sqrt(mean_squared_error(y_test, y_pred)),\n","    \"Mean Absolute Error\": mean_absolute_error(y_test, y_pred),\n","    \"Mean Absolute Percentage Error\": mean_absolute_percentage_error(y_test, y_pred),\n","    \"R-Squared\": r2_score(y_test, y_pred),\n","    \"Explained Variance\": explained_variance_score(y_test, y_pred)\n","}\n","\n","# Print metrics\n","for metric_name, metric_value in regression_metrics.items():\n","    print(f\"{metric_name}: {metric_value:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MIxJhkC3K8YJ","executionInfo":{"status":"ok","timestamp":1755436602500,"user_tz":300,"elapsed":113,"user":{"displayName":"Bibhu Mishra","userId":"12646824449670614646"}},"outputId":"04197f98-6c90-4b2a-82af-e1c61e9e0aa2"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean Squared Error: 21488822.8615\n","Root Mean Squared Error: 4635.6038\n","Mean Absolute Error: 2621.6771\n","Mean Absolute Percentage Error: 0.3361\n","R-Squared: 0.8543\n","Explained Variance: 0.8561\n"]}]},{"cell_type":"markdown","source":["## Random Forest"],"metadata":{"id":"TvqB_wteLPUC"}},{"cell_type":"code","source":["\"\"\"\n","Insurance Cost Prediction using Random Forest Regressor with a Scikit-Learn Pipeline\n","-----------------------------------------------------------------------------------\n","\n","This script demonstrates how to build a machine learning pipeline for regression\n","tasks (predicting insurance charges). It includes preprocessing steps for\n","numerical and categorical features, and model evaluation with regression metrics.\n","\n","Key Steps:\n","1. Preprocessing numerical & categorical features.\n","2. Building a full ML pipeline with Random Forest Regressor.\n","3. Training & predicting on train/test data.\n","4. Evaluating performance using regression metrics.\n","\"\"\"\n","\n","# -----------------------------\n","# Imports\n","# -----------------------------\n","import numpy as np\n","import pandas as pd\n","\n","# Preprocessing & pipeline tools\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler\n","from sklearn.impute import SimpleImputer\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","\n","# Model\n","from sklearn.ensemble import RandomForestRegressor\n","\n","# Evaluation metrics (for regression)\n","from sklearn.metrics import (\n","    mean_squared_error,\n","    mean_absolute_error,\n","    mean_absolute_percentage_error,\n","    r2_score,\n","    explained_variance_score\n",")\n","\n","# -----------------------------\n","# Load Dataset\n","# -----------------------------\n","# Example: load your insurance dataset\n","# df = pd.read_csv(\"/content/drive/MyDrive/edurekaai/_data/insurance_cost.csv\")\n","\n","# Define features and target\n","# X = df.drop(columns=[\"charges\"])\n","# y = df[\"charges\"]\n","\n","# Assume X_train, X_test, y_train, y_test are already created\n","# (e.g., using train_test_split)\n","\n","# -----------------------------\n","# Feature Types\n","# -----------------------------\n","# Separate numerical and categorical feature names\n","numerical_features = X_train.select_dtypes(exclude=[\"object\", \"category\"]).columns\n","categorical_features = X_train.select_dtypes(include=[\"object\", \"category\"]).columns\n","\n","# -----------------------------\n","# Preprocessing Pipelines\n","# -----------------------------\n","\n","# 1. Numerical Transformer:\n","#    - Fill missing values with median\n","#    - Standardize features (not required for trees, but kept for consistency)\n","num_transformer = Pipeline(steps=[\n","    (\"imputer\", SimpleImputer(strategy=\"median\")),\n","    (\"scaler\", StandardScaler())\n","])\n","\n","# 2. Categorical Transformer:\n","#    - Apply OneHotEncoding to handle categorical variables\n","#    - Ignore unknown categories at prediction time\n","cat_transformer = Pipeline(steps=[\n","    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n","])\n","\n","# 3. Combine Numerical & Categorical Preprocessing\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        (\"num\", num_transformer, numerical_features),\n","        (\"cat\", cat_transformer, categorical_features)\n","    ]\n",")\n","\n","# -----------------------------\n","# Full Model Pipeline\n","# -----------------------------\n","# Combine preprocessing and regression into a single pipeline\n","model = Pipeline(steps=[\n","    (\"preprocessor\", preprocessor),\n","    (\"regressor\", RandomForestRegressor(\n","        n_estimators=200,       # number of trees\n","        max_depth=10,           # limit depth to control overfitting\n","        random_state=42,\n","        n_jobs=-1               # use all CPU cores\n","    ))\n","])\n","\n","# -----------------------------\n","# Model Training\n","# -----------------------------\n","# Train the pipeline on training data\n","model.fit(X_train, y_train)\n","\n","# -----------------------------\n","# Prediction\n","# -----------------------------\n","y_pred = model.predict(X_test)\n","\n","# -----------------------------\n","# Model Evaluation\n","# -----------------------------\n","regression_metrics = {\n","    \"Mean Squared Error\": mean_squared_error(y_test, y_pred),\n","    \"Root Mean Squared Error\": np.sqrt(mean_squared_error(y_test, y_pred)),\n","    \"Mean Absolute Error\": mean_absolute_error(y_test, y_pred),\n","    \"Mean Absolute Percentage Error\": mean_absolute_percentage_error(y_test, y_pred),\n","    \"R-Squared\": r2_score(y_test, y_pred),\n","    \"Explained Variance\": explained_variance_score(y_test, y_pred)\n","}\n","\n","# Print metrics\n","for metric_name, metric_value in regression_metrics.items():\n","    print(f\"{metric_name}: {metric_value:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4EV6RzznLRWx","executionInfo":{"status":"ok","timestamp":1755436655836,"user_tz":300,"elapsed":861,"user":{"displayName":"Bibhu Mishra","userId":"12646824449670614646"}},"outputId":"d4372268-d46f-41b8-91bd-7fb423a8b7f3"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean Squared Error: 21999872.9028\n","Root Mean Squared Error: 4690.4022\n","Mean Absolute Error: 2787.3832\n","Mean Absolute Percentage Error: 0.3733\n","R-Squared: 0.8509\n","Explained Variance: 0.8542\n"]}]},{"cell_type":"markdown","source":["## Ada Boost"],"metadata":{"id":"z-jwIxLBLmzc"}},{"cell_type":"code","source":["\"\"\"\n","Insurance Cost Prediction using AdaBoost Regressor with a Scikit-Learn Pipeline\n","-------------------------------------------------------------------------------\n","\n","This script demonstrates how to build a machine learning pipeline for regression\n","tasks (predicting insurance charges). It includes preprocessing steps for\n","numerical and categorical features, and model evaluation with regression metrics.\n","\n","Key Steps:\n","1. Preprocessing numerical & categorical features.\n","2. Building a full ML pipeline with AdaBoost Regressor.\n","3. Training & predicting on train/test data.\n","4. Evaluating performance using regression metrics.\n","\"\"\"\n","\n","# -----------------------------\n","# Imports\n","# -----------------------------\n","import numpy as np\n","import pandas as pd\n","\n","# Preprocessing & pipeline tools\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler\n","from sklearn.impute import SimpleImputer\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","\n","# Model\n","from sklearn.ensemble import AdaBoostRegressor\n","from sklearn.tree import DecisionTreeRegressor\n","\n","# Evaluation metrics (for regression)\n","from sklearn.metrics import (\n","    mean_squared_error,\n","    mean_absolute_error,\n","    mean_absolute_percentage_error,\n","    r2_score,\n","    explained_variance_score\n",")\n","\n","# -----------------------------\n","# Load Dataset\n","# -----------------------------\n","# Example: load your insurance dataset\n","# df = pd.read_csv(\"/content/drive/MyDrive/edurekaai/_data/insurance_cost.csv\")\n","\n","# Define features and target\n","# X = df.drop(columns=[\"charges\"])\n","# y = df[\"charges\"]\n","\n","# Assume X_train, X_test, y_train, y_test are already created\n","# (e.g., using train_test_split)\n","\n","# -----------------------------\n","# Feature Types\n","# -----------------------------\n","# Separate numerical and categorical feature names\n","numerical_features = X_train.select_dtypes(exclude=[\"object\", \"category\"]).columns\n","categorical_features = X_train.select_dtypes(include=[\"object\", \"category\"]).columns\n","\n","# -----------------------------\n","# Preprocessing Pipelines\n","# -----------------------------\n","\n","# 1. Numerical Transformer:\n","#    - Fill missing values with median\n","#    - Standardize features (optional for trees, but included for consistency)\n","num_transformer = Pipeline(steps=[\n","    (\"imputer\", SimpleImputer(strategy=\"median\")),\n","    (\"scaler\", StandardScaler())\n","])\n","\n","# 2. Categorical Transformer:\n","#    - Apply OneHotEncoding to handle categorical variables\n","#    - Ignore unknown categories at prediction time\n","cat_transformer = Pipeline(steps=[\n","    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n","])\n","\n","# 3. Combine Numerical & Categorical Preprocessing\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        (\"num\", num_transformer, numerical_features),\n","        (\"cat\", cat_transformer, categorical_features)\n","    ]\n",")\n","\n","# -----------------------------\n","# Full Model Pipeline\n","# -----------------------------\n","# Use AdaBoost Regressor with DecisionTreeRegressor as base estimator\n","model = Pipeline(steps=[\n","    (\"preprocessor\", preprocessor),\n","    (\"regressor\", AdaBoostRegressor(\n","        estimator=DecisionTreeRegressor(max_depth=4),\n","        n_estimators=200,\n","        learning_rate=0.05,\n","        random_state=42\n","    ))\n","])\n","\n","# -----------------------------\n","# Model Training\n","# -----------------------------\n","# Train the pipeline on training data\n","model.fit(X_train, y_train)\n","\n","# -----------------------------\n","# Prediction\n","# -----------------------------\n","y_pred = model.predict(X_test)\n","\n","# -----------------------------\n","# Model Evaluation\n","# -----------------------------\n","regression_metrics = {\n","    \"Mean Squared Error\": mean_squared_error(y_test, y_pred),\n","    \"Root Mean Squared Error\": np.sqrt(mean_squared_error(y_test, y_pred)),\n","    \"Mean Absolute Error\": mean_absolute_error(y_test, y_pred),\n","    \"Mean Absolute Percentage Error\": mean_absolute_percentage_error(y_test, y_pred),\n","    \"R-Squared\": r2_score(y_test, y_pred),\n","    \"Explained Variance\": explained_variance_score(y_test, y_pred)\n","}\n","\n","# Print metrics\n","for metric_name, metric_value in regression_metrics.items():\n","    print(f\"{metric_name}: {metric_value:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yVR38hMqLpie","executionInfo":{"status":"ok","timestamp":1755436725623,"user_tz":300,"elapsed":548,"user":{"displayName":"Bibhu Mishra","userId":"12646824449670614646"}},"outputId":"1788d671-2867-4126-b842-8c44d809b9e9"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean Squared Error: 27208408.7183\n","Root Mean Squared Error: 5216.1680\n","Mean Absolute Error: 4360.7773\n","Mean Absolute Percentage Error: 0.7847\n","R-Squared: 0.8156\n","Explained Variance: 0.8620\n"]}]},{"cell_type":"markdown","source":["## Gradient Boost"],"metadata":{"id":"JQdUrBCtLs1e"}},{"cell_type":"code","source":["\"\"\"\n","Insurance Cost Prediction using Gradient Boosting Regressor with a Scikit-Learn Pipeline\n","----------------------------------------------------------------------------------------\n","\n","This script demonstrates how to build a machine learning pipeline for regression\n","tasks (predicting insurance charges). It includes preprocessing steps for\n","numerical and categorical features, and model evaluation with regression metrics.\n","\n","Key Steps:\n","1. Preprocessing numerical & categorical features.\n","2. Building a full ML pipeline with Gradient Boosting Regressor.\n","3. Training & predicting on train/test data.\n","4. Evaluating performance using regression metrics.\n","\"\"\"\n","\n","# -----------------------------\n","# Imports\n","# -----------------------------\n","import numpy as np\n","import pandas as pd\n","\n","# Preprocessing & pipeline tools\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler\n","from sklearn.impute import SimpleImputer\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","\n","# Model\n","from sklearn.ensemble import GradientBoostingRegressor\n","\n","# Evaluation metrics (for regression)\n","from sklearn.metrics import (\n","    mean_squared_error,\n","    mean_absolute_error,\n","    mean_absolute_percentage_error,\n","    r2_score,\n","    explained_variance_score\n",")\n","\n","# -----------------------------\n","# Load Dataset\n","# -----------------------------\n","# Example: load your insurance dataset\n","# df = pd.read_csv(\"/content/drive/MyDrive/edurekaai/_data/insurance_cost.csv\")\n","\n","# Define features and target\n","# X = df.drop(columns=[\"charges\"])\n","# y = df[\"charges\"]\n","\n","# Assume X_train, X_test, y_train, y_test are already created\n","# (e.g., using train_test_split)\n","\n","# -----------------------------\n","# Feature Types\n","# -----------------------------\n","numerical_features = X_train.select_dtypes(exclude=[\"object\", \"category\"]).columns\n","categorical_features = X_train.select_dtypes(include=[\"object\", \"category\"]).columns\n","\n","# -----------------------------\n","# Preprocessing Pipelines\n","# -----------------------------\n","num_transformer = Pipeline(steps=[\n","    (\"imputer\", SimpleImputer(strategy=\"median\")),\n","    (\"scaler\", StandardScaler())\n","])\n","\n","cat_transformer = Pipeline(steps=[\n","    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n","])\n","\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        (\"num\", num_transformer, numerical_features),\n","        (\"cat\", cat_transformer, categorical_features)\n","    ]\n",")\n","\n","# -----------------------------\n","# Full Model Pipeline\n","# -----------------------------\n","model = Pipeline(steps=[\n","    (\"preprocessor\", preprocessor),\n","    (\"regressor\", GradientBoostingRegressor(\n","        n_estimators=300,\n","        learning_rate=0.05,\n","        max_depth=4,\n","        random_state=42\n","    ))\n","])\n","\n","# -----------------------------\n","# Model Training\n","# -----------------------------\n","model.fit(X_train, y_train)\n","\n","# -----------------------------\n","# Prediction\n","# -----------------------------\n","y_pred = model.predict(X_test)\n","\n","# -----------------------------\n","# Model Evaluation\n","# -----------------------------\n","regression_metrics = {\n","    \"Mean Squared Error\": mean_squared_error(y_test, y_pred),\n","    \"Root Mean Squared Error\": np.sqrt(mean_squared_error(y_test, y_pred)),\n","    \"Mean Absolute Error\": mean_absolute_error(y_test, y_pred),\n","    \"Mean Absolute Percentage Error\": mean_absolute_percentage_error(y_test, y_pred),\n","    \"R-Squared\": r2_score(y_test, y_pred),\n","    \"Explained Variance\": explained_variance_score(y_test, y_pred)\n","}\n","\n","for metric_name, metric_value in regression_metrics.items():\n","    print(f\"{metric_name}: {metric_value:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HOHnOhpBL0Bj","executionInfo":{"status":"ok","timestamp":1755436783470,"user_tz":300,"elapsed":899,"user":{"displayName":"Bibhu Mishra","userId":"12646824449670614646"}},"outputId":"17abf826-0abc-4ce3-e7a9-c9601ef7a5d2"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean Squared Error: 21701033.3464\n","Root Mean Squared Error: 4658.4368\n","Mean Absolute Error: 2681.1650\n","Mean Absolute Percentage Error: 0.3393\n","R-Squared: 0.8529\n","Explained Variance: 0.8541\n"]}]},{"cell_type":"markdown","source":["## XGBoost"],"metadata":{"id":"D9ifbQ8sMARS"}},{"cell_type":"code","source":["\"\"\"\n","Insurance Cost Prediction using XGBoost Regressor with a Scikit-Learn Pipeline\n","-------------------------------------------------------------------------------\n","\n","This script demonstrates how to build a machine learning pipeline for regression\n","tasks (predicting insurance charges). It includes preprocessing steps for\n","numerical and categorical features, and model evaluation with regression metrics.\n","\n","Key Steps:\n","1. Preprocessing numerical & categorical features.\n","2. Building a full ML pipeline with XGBoost Regressor.\n","3. Training & predicting on train/test data.\n","4. Evaluating performance using regression metrics.\n","\"\"\"\n","\n","# -----------------------------\n","# Imports\n","# -----------------------------\n","import numpy as np\n","import pandas as pd\n","\n","# Preprocessing & pipeline tools\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler\n","from sklearn.impute import SimpleImputer\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","\n","# Model\n","from xgboost import XGBRegressor\n","\n","# Evaluation metrics (for regression)\n","from sklearn.metrics import (\n","    mean_squared_error,\n","    mean_absolute_error,\n","    mean_absolute_percentage_error,\n","    r2_score,\n","    explained_variance_score\n",")\n","\n","# -----------------------------\n","# Load Dataset\n","# -----------------------------\n","# Example: load your insurance dataset\n","# df = pd.read_csv(\"/content/drive/MyDrive/edurekaai/_data/insurance_cost.csv\")\n","\n","# Define features and target\n","# X = df.drop(columns=[\"charges\"])\n","# y = df[\"charges\"]\n","\n","# Assume X_train, X_test, y_train, y_test are already created\n","# (e.g., using train_test_split)\n","\n","# -----------------------------\n","# Feature Types\n","# -----------------------------\n","numerical_features = X_train.select_dtypes(exclude=[\"object\", \"category\"]).columns\n","categorical_features = X_train.select_dtypes(include=[\"object\", \"category\"]).columns\n","\n","# -----------------------------\n","# Preprocessing Pipelines\n","# -----------------------------\n","num_transformer = Pipeline(steps=[\n","    (\"imputer\", SimpleImputer(strategy=\"median\")),\n","    (\"scaler\", StandardScaler())\n","])\n","\n","cat_transformer = Pipeline(steps=[\n","    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n","])\n","\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        (\"num\", num_transformer, numerical_features),\n","        (\"cat\", cat_transformer, categorical_features)\n","    ]\n",")\n","\n","# -----------------------------\n","# Full Model Pipeline\n","# -----------------------------\n","model = Pipeline(steps=[\n","    (\"preprocessor\", preprocessor),\n","    (\"regressor\", XGBRegressor(\n","        n_estimators=300,\n","        learning_rate=0.05,\n","        max_depth=4,\n","        subsample=0.8,\n","        colsample_bytree=0.8,\n","        random_state=42,\n","        n_jobs=-1\n","    ))\n","])\n","\n","# -----------------------------\n","# Model Training\n","# -----------------------------\n","model.fit(X_train, y_train)\n","\n","# -----------------------------\n","# Prediction\n","# -----------------------------\n","y_pred = model.predict(X_test)\n","\n","# -----------------------------\n","# Model Evaluation\n","# -----------------------------\n","regression_metrics = {\n","    \"Mean Squared Error\": mean_squared_error(y_test, y_pred),\n","    \"Root Mean Squared Error\": np.sqrt(mean_squared_error(y_test, y_pred)),\n","    \"Mean Absolute Error\": mean_absolute_error(y_test, y_pred),\n","    \"Mean Absolute Percentage Error\": mean_absolute_percentage_error(y_test, y_pred),\n","    \"R-Squared\": r2_score(y_test, y_pred),\n","    \"Explained Variance\": explained_variance_score(y_test, y_pred)\n","}\n","\n","for metric_name, metric_value in regression_metrics.items():\n","    print(f\"{metric_name}: {metric_value:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nbt0f3NxMCzl","executionInfo":{"status":"ok","timestamp":1755436842985,"user_tz":300,"elapsed":757,"user":{"displayName":"Bibhu Mishra","userId":"12646824449670614646"}},"outputId":"1d57a57a-992d-4636-fa29-ffb203ae7449"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean Squared Error: 20670567.0032\n","Root Mean Squared Error: 4546.4895\n","Mean Absolute Error: 2716.9160\n","Mean Absolute Percentage Error: 0.3478\n","R-Squared: 0.8599\n","Explained Variance: 0.8608\n"]}]}]}