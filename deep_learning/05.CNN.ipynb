{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO6VYVtgJxNdzZMggv/dn2j"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### **Convolutional Neural Network (CNN)**\n","**CNN** is a specialized deep-learning **ANN** architecture that is designed for image processing, computer vision, and spatial data analysis. It is used for object detection, face recognition, self-driving, etc...\n","\n","**CNN** = **Convolutional Network** + **Pooling** + **ANN**\n","\n","\n","**CNN** is nothing but ANN with feature engineering. The first thing we do is **we extract features** from the image, **compress the image features** and then send the feaures to the ANN for processing.\n","\n","**Why ANN alone is not good enough for image processing?**\n","- Say you have a color image of 50 x 50 pixels\n","\n","- A color is combination 3 channels: R G B.\n","\n","- Hence, the image is made of 50 x 50 x 3 = 7500 pixels.\n","\n","- But pixels alone does not identify the object in the image. **You need spatial features ALSO.**\n","\n","- A 3 minutes video captured using 60Hz camera gives you nearly 10000 frames or images.\n","\n","- You end up having **10000 x 7500 = 75, 000, 000 pixels** which is  huge data to process a 3 minute video.\n","\n","- **_Hence, along with Spatial features, you also need data compression or sample downsizing._***\n","\n","- This explains why ANN alone is not enough for image processing.\n","\n","#### **Solution**\n","You need **Convolution Network** and **Pooling**. **Convolution Network** extracts the spatial features from the image, and **Pooling** does the sample or feature downsizing.\n","\n","![CNN](https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41598-024-51258-6/MediaObjects/41598_2024_51258_Fig1_HTML.png?as=webp)\n","\n","https://poloclub.github.io/cnn-explainer/\n"],"metadata":{"id":"3aT9fTnzAGYX"}},{"cell_type":"markdown","source":["### 1. Convolution Network / Layer\n","**A convolution layer is the core building block of a Convolutional Neural Network (CNN)**. It is designed to automatically extract spatial features from input data (usually from images) using a set of learnable filters or kernels.\n","\n","**Imagine**\n","\n","You have an image represented as a grid of pixel values (e.g., 7x7 color scale). The convolution layer slides a small filter (like 3x3 ) over the image and performs element-wise multiplication and summation to produce a feature map (also called an activation map).\n","\n","![CNN](https://miro.medium.com/v2/resize:fit:1100/format:webp/1*ciDgQEjViWLnCbmX-EeSrA.gif)\n","\n","Popular Kernel Sizes are:\n","- 7 x 7 (used usually in the first convolution layer for large images)\n","- 5 x 5\n","- 3 x 3\n","\n","**even number kernel is not used because it fails to capture the center of the image.\n","\n","**Note**\n","- ***One kernel / filter mean one feature***. Hence, more feature you need, more kernel needs to be added.\n","- If we need minute details from the image, we will have to apply multiple filters. (Popular filter sizes are 16, 32, and 64.\n","- More feature, more complex is the model.\n","- **_An activation function applied after convolution to introduce non-linearity, which helps the network learn complex patterns._**\n","\n","**Other Parameters in Convolutional Operation**\n","\n","- **Stride**: Stride indicates how many pixels the kernel should be shifted over at a time.The impact stride has on a CNN is similar to kernel size.\n","When stride is set to 1, the filter moves across one pixel at a time, and when the stride is set to 2, the filter moves across two pixels at a time.\n","The higher the stride value, the smaller the output, and vice versa.\n","\n","- **Padding**: Padding is often necessary when the kernel extends beyond the activation map.\n","\n"],"metadata":{"id":"DO_kwu34E0Au"}},{"cell_type":"markdown","source":["### 2. Pooling\n","**Pooling** is a downsampling operation used in Convolutional Neural Networks (CNNs) to reduce the spatial size (width × height) of feature maps, while retaining important features. It is done to decrease computational load and control overfitting.\n","\n","#### Max Pooling vs Average Pooling\n","\n","![Pooling](https://cdn.analyticsvidhya.com/wp-content/uploads/2024/08/597371-kqieqhxzicu7thjaqbfpbq-66c7045e59b1e.webp)\n","\n"],"metadata":{"id":"eqmnJS0n0aha"}},{"cell_type":"markdown","source":["### 3. Fully Connected (Dense) Layers\n","Dense layer is nothing, but the ANN layer. **After several** convolutional and pooling layers, the feature maps are flattened and passed to fully connected layers for classification or regression."],"metadata":{"id":"KWW7RudB3tV9"}},{"cell_type":"markdown","source":["### 4. Dropout (optional)\n","Dropout is a regularization technique used during training to prevent overfitting by randomly \"dropping out\" (turning off) a fraction of the neurons in a layer during each training step."],"metadata":{"id":"fLe1XrP_4pn0"}},{"cell_type":"markdown","source":["## A Simple CNN Code"],"metadata":{"id":"Y7QbJB1N5bAI"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.utils import to_categorical\n","from matplotlib import pyplot as plt\n","\n","# Load and preprocess the data\n","# x_train is a 3 dimensional array 60000 x 28 x 28 --> 60000 training images. Each image is of \"28 x 28\" pixel image showing hand-written digit sample.\n","# Each element in the x_train (i.e. x_train[][][] is a digit representing gray color code in the 0-255 scale)\n","# y_train is a 1 dimensional array 60000 --> Each element is numeric representation of image in x_train\n","\n","# x_test is a 3 dimensional array 10000 x 28 x 28 --> 10000 training images. Each image is of \"28 x 28\" pixel image showing hand-written digit sample.\n","# Each element in the x_test (i.e. x_train[][][] is a digit representing gray color code in the 0-255 scale)\n","# y_test is a 1 dimensional array 10000 --> Each element is numeric representation of image in x_test\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","# print(x_train.shape)\n","\n","# plt.imshow(x_train[0]) # its gray scale image. but matplot applies default viridis color\n","# plt.imshow(x_train[0], cmap=\"gray\")\n","# plt.show()\n","\n","\n","# Reshape and normalize the numerical data\n","## It reshapes 3D array 60000 x 28 x 28 to 4D array 60000 x 28 x 28 x 1\n","## the last columun represents the no of channel. Since our image is in gray scale, it has one channel. The last column stores 1 always.\n","## Why to 4D? Because the CNN architecture expects it in that format.\n","# x_train[] --> Image Index (0 - 59999)\n","# x_train[][] --> Image Pixel Row Index (0 - 27)\n","# x_train[][][] --> Image Pixel Column Index (0 - 27)\n","# x_train[][][][] --> Color Channel (1-3 for colored images, 1 for grayscaled images)\n","x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255\n","x_test  = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255\n","# print(x_train.shape)\n","\n","# Normalize the categorical data (target)\n","## Target here represents the hand-written digit class ranging from 0-9\n","## to_categorical() does one-hot encoding on it.\n","## one-hot encoding is must of loss function \"categorical_crossentropy\"\n","print(y_train[0])\n","y_train = to_categorical(y_train)\n","y_test  = to_categorical(y_test)\n","print(y_train[0])\n","\n","# Build CNN model\n","model = models.Sequential([\n","    # Convolution Layer1 - Apply 32 filter/kernel of 3x3 size\n","    # Each image dimension is 28 x 28 x 1. Hence, the imput layer should have 784 neurons to read each pixel.\n","    # input_shape=(28, 28, 1) defines the input layer neurons\n","    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n","    layers.MaxPooling2D((2, 2)), # Pooling using 2x2 filter\n","\n","    # Convolution Layer2 - Apply 64 filter/kernel of 3x3 size\n","    ## input_shape() is not specified here. Keras determines the shape and passes it automatically.\n","    layers.Conv2D(64, (3, 3), activation='relu'),\n","    layers.MaxPooling2D((2, 2)),\n","\n","\n","    layers.Flatten(), # Convert 2D array to 1D array input\n","\n","    # Here comes the ANN layers\n","    layers.Dense(64, activation='relu'),    # ANN Hidden/Dense layer with 64 neurons\n","    layers.Dense(10, activation='softmax')  # 10 classes for MNIST (It is a multiclass of 10 predicting class 0 to 9 digit)\n","])\n","\n","# Compile and train the model\n","model.compile(optimizer='adam',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","model.fit(x_train, y_train, epochs=4, validation_data=(x_test, y_test))\n","\n","\n"],"metadata":{"id":"1bt-Uns10aLb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1754595400380,"user_tz":420,"elapsed":303672,"user":{"displayName":"Bibhu Mishra","userId":"12646824449670614646"}},"outputId":"da16ec1b-bcaa-489e-e1db-f4d23b609694"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["5\n","[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/4\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 38ms/step - accuracy: 0.9049 - loss: 0.3037 - val_accuracy: 0.9851 - val_loss: 0.0487\n","Epoch 2/4\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 38ms/step - accuracy: 0.9851 - loss: 0.0493 - val_accuracy: 0.9878 - val_loss: 0.0359\n","Epoch 3/4\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 39ms/step - accuracy: 0.9888 - loss: 0.0337 - val_accuracy: 0.9914 - val_loss: 0.0276\n","Epoch 4/4\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 37ms/step - accuracy: 0.9929 - loss: 0.0227 - val_accuracy: 0.9895 - val_loss: 0.0301\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9853 - loss: 0.0399\n","Test accuracy: 0.9894999861717224\n"]}]},{"cell_type":"code","source":["# Evaluate on training data\n","train_loss, train_acc = model.evaluate(x_train, y_train)\n","print(\"Training accuracy:\", train_acc)\n","\n","# Evaluate on test data\n","test_loss, test_acc = model.evaluate(x_test, y_test)\n","print(\"Test accuracy:\", test_acc)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TNuBk25ICeMK","executionInfo":{"status":"ok","timestamp":1754595713427,"user_tz":420,"elapsed":46687,"user":{"displayName":"Bibhu Mishra","userId":"12646824449670614646"}},"outputId":"47ff6d85-3b8d-4c7b-debf-e7183fc3ad8f"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.9955 - loss: 0.0133\n","Training accuracy: 0.9958999752998352\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9853 - loss: 0.0399\n","Test accuracy: 0.9894999861717224\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","from sklearn.metrics import accuracy_score\n","\n","# 1. Predict probabilities for test data\n","pred = model.predict(x_test)\n","\n","# 2. Get predicted class labels by taking argmax\n","y_pred = tf.argmax(pred, axis=1).numpy()  # convert to NumPy array\n","\n","# 3. If y_test is one-hot encoded, convert it back to class labels\n","if len(y_test.shape) > 1 and y_test.shape[1] > 1:\n","    y_true = tf.argmax(y_test, axis=1).numpy()\n","else:\n","    y_true = y_test\n","\n","# 4. Compute accuracy\n","acc = accuracy_score(y_true, y_pred)\n","print(f\"Test accuracy (manual): {acc:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TakV9Qe988Ih","executionInfo":{"status":"ok","timestamp":1754595792979,"user_tz":420,"elapsed":5297,"user":{"displayName":"Bibhu Mishra","userId":"12646824449670614646"}},"outputId":"6c533e5b-f6d1-4f3e-83c5-bf73e5c5f92a"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step\n","Test accuracy (manual): 0.9895\n"]}]}]}